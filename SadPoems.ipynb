{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sad Poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.width', 1000)\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "import requests as rq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Poem</th>\n",
       "      <th>Poet</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>\\r\\r\\n                    Invisible Fish\\r\\r\\n...</td>\n",
       "      <td>\\r\\r\\nInvisible fish swim this ghost ocean now...</td>\n",
       "      <td>Joy Harjo</td>\n",
       "      <td>Living,Time &amp; Brevity,Relationships,Family &amp; A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>\\r\\r\\n                    Don’t Bother the Ear...</td>\n",
       "      <td>\\r\\r\\nDon’t bother the earth spirit who lives ...</td>\n",
       "      <td>Joy Harjo</td>\n",
       "      <td>Religion,The Spiritual,Mythology &amp; Folklore,Fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>\\r\\r\\n                    [\"Hour in which I co...</td>\n",
       "      <td>\\r\\r\\nHour in which I consider hydrangea, a sa...</td>\n",
       "      <td>Simone White</td>\n",
       "      <td>Living,Parenthood,The Body,The Mind,Nature,Tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>\\r\\r\\n                    scars\\r\\r\\n         ...</td>\n",
       "      <td>\\r\\r\\nmy father’s body is a map\\r\\r\\na record ...</td>\n",
       "      <td>Truong Tran</td>\n",
       "      <td>The Body,Family &amp; Ancestors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>\\r\\r\\n                    what remains two\\r\\r...</td>\n",
       "      <td>\\r\\r\\nit has long been forgotten this practice...</td>\n",
       "      <td>Truong Tran</td>\n",
       "      <td>Infancy,Parenthood,The Body</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                              Title  \\\n",
       "6            6  \\r\\r\\n                    Invisible Fish\\r\\r\\n...   \n",
       "7            7  \\r\\r\\n                    Don’t Bother the Ear...   \n",
       "9            9  \\r\\r\\n                    [\"Hour in which I co...   \n",
       "16          16  \\r\\r\\n                    scars\\r\\r\\n         ...   \n",
       "17          17  \\r\\r\\n                    what remains two\\r\\r...   \n",
       "\n",
       "                                                 Poem          Poet  \\\n",
       "6   \\r\\r\\nInvisible fish swim this ghost ocean now...     Joy Harjo   \n",
       "7   \\r\\r\\nDon’t bother the earth spirit who lives ...     Joy Harjo   \n",
       "9   \\r\\r\\nHour in which I consider hydrangea, a sa...  Simone White   \n",
       "16  \\r\\r\\nmy father’s body is a map\\r\\r\\na record ...   Truong Tran   \n",
       "17  \\r\\r\\nit has long been forgotten this practice...   Truong Tran   \n",
       "\n",
       "                                                 Tags  \n",
       "6   Living,Time & Brevity,Relationships,Family & A...  \n",
       "7   Religion,The Spiritual,Mythology & Folklore,Fa...  \n",
       "9   Living,Parenthood,The Body,The Mind,Nature,Tre...  \n",
       "16                        The Body,Family & Ancestors  \n",
       "17                        Infancy,Parenthood,The Body  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading additional nature poems from poetryfoundation.com dataset\n",
    "df2 = pd.read_csv('PoetryFoundationData.csv') # load dataset\n",
    "df2 = df2.dropna()\n",
    "df2.head() # getting top 5 head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchfor = ['Sorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting additional poems that contain the tag Love \n",
    "poems2 = df2['Poem']\n",
    "sadPoems = poems2.loc[df2['Tags'].str.contains('|'.join(searchfor))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28    \\r\\r\\nNothing can reach you now, not lead or s...\n",
       "29    \\r\\r\\nAmong physicians rich in their death wat...\n",
       "30    \\r\\r\\nImagine half your face\\r\\r\\nrubbed out y...\n",
       "47    \\r\\r\\nThe   first    great    poet  of\\r\\r\\nth...\n",
       "73    \\r\\r\\nWhen I was three,\\r\\r\\na tsunami hit tow...\n",
       "Name: Poem, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sadPoems.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert nature series to a string\n",
    "sadPoems = sadPoems.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPPING CHARACTERS: for nature poems, Make two dictionaries , one to convert chars to ints, the other to convert ints back to chars\n",
    "\n",
    "chars = sorted(list(set(sadPoems)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the dataset:\n",
    "seqlen = 50\n",
    "step = seqlen\n",
    "\n",
    "data_X = []\n",
    "data_y = []\n",
    "\n",
    "poemLines = [] \n",
    "\n",
    "# creates poem lines \n",
    "for i in range(0, len(sadPoems) - seqlen - 1, step):\n",
    "    poemLines.append(sadPoems[i: i + seqlen + 1])\n",
    "    \n",
    "# creating x and y data\n",
    "data_X = np.zeros((len(poemLines), seqlen, len(chars)), dtype=np.bool)\n",
    "data_Y = np.zeros((len(poemLines), seqlen, len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, poemLines in enumerate(poemLines):\n",
    "    for t, (char_in, char_out) in enumerate(zip(poemLines[:-1], poemLines[1:])):\n",
    "        data_X[i, t, char_indices[char_in]] = 1\n",
    "        data_Y[i, t, char_indices[char_out]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50, 128)           115712    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50, 97)            12513     \n",
      "=================================================================\n",
      "Total params: 128,225\n",
      "Trainable params: 128,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01), metrics=['categorical_crossentropy', 'accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 3.6518 - categorical_crossentropy: 3.6518 - accuracy: 0.1667\n",
      "Epoch 2/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 3.1527 - categorical_crossentropy: 3.1527 - accuracy: 0.2185\n",
      "Epoch 3/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 3.0622 - categorical_crossentropy: 3.0622 - accuracy: 0.2714\n",
      "Epoch 4/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 2.9127 - categorical_crossentropy: 2.9127 - accuracy: 0.2976\n",
      "Epoch 5/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 2.6151 - categorical_crossentropy: 2.6151 - accuracy: 0.3578\n",
      "Epoch 6/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 2.3471 - categorical_crossentropy: 2.3471 - accuracy: 0.3997\n",
      "Epoch 7/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 2.1913 - categorical_crossentropy: 2.1913 - accuracy: 0.4273\n",
      "Epoch 8/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 2.1114 - categorical_crossentropy: 2.1114 - accuracy: 0.4292\n",
      "Epoch 9/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 2.0440 - categorical_crossentropy: 2.0440 - accuracy: 0.4365\n",
      "Epoch 10/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.9707 - categorical_crossentropy: 1.9707 - accuracy: 0.4481\n",
      "Epoch 11/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.8961 - categorical_crossentropy: 1.8961 - accuracy: 0.4720\n",
      "Epoch 12/80\n",
      "993/993 [==============================] - 3s 3ms/step - loss: 1.9124 - categorical_crossentropy: 1.9124 - accuracy: 0.4622\n",
      "Epoch 13/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.8156 - categorical_crossentropy: 1.8156 - accuracy: 0.4897\n",
      "Epoch 14/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.8012 - categorical_crossentropy: 1.8012 - accuracy: 0.4934\n",
      "Epoch 15/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.7916 - categorical_crossentropy: 1.7916 - accuracy: 0.4884\n",
      "Epoch 16/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.7414 - categorical_crossentropy: 1.7414 - accuracy: 0.5046\n",
      "Epoch 17/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.6941 - categorical_crossentropy: 1.6941 - accuracy: 0.5160\n",
      "Epoch 18/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.6852 - categorical_crossentropy: 1.6852 - accuracy: 0.5150\n",
      "Epoch 19/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.6522 - categorical_crossentropy: 1.6522 - accuracy: 0.5182\n",
      "Epoch 20/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.6267 - categorical_crossentropy: 1.6267 - accuracy: 0.5299\n",
      "Epoch 21/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.6093 - categorical_crossentropy: 1.6093 - accuracy: 0.5276\n",
      "Epoch 22/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.5844 - categorical_crossentropy: 1.5844 - accuracy: 0.5395\n",
      "Epoch 23/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.5675 - categorical_crossentropy: 1.5675 - accuracy: 0.5396\n",
      "Epoch 24/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.5440 - categorical_crossentropy: 1.5440 - accuracy: 0.5469\n",
      "Epoch 25/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.5390 - categorical_crossentropy: 1.5390 - accuracy: 0.5452\n",
      "Epoch 26/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.5002 - categorical_crossentropy: 1.5002 - accuracy: 0.5597\n",
      "Epoch 27/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.5034 - categorical_crossentropy: 1.5034 - accuracy: 0.5548\n",
      "Epoch 28/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.4700 - categorical_crossentropy: 1.4700 - accuracy: 0.5675\n",
      "Epoch 29/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.4522 - categorical_crossentropy: 1.4522 - accuracy: 0.5713\n",
      "Epoch 30/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.4451 - categorical_crossentropy: 1.4451 - accuracy: 0.5717\n",
      "Epoch 31/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.4481 - categorical_crossentropy: 1.4481 - accuracy: 0.5713\n",
      "Epoch 32/80\n",
      "993/993 [==============================] - 2s 3ms/step - loss: 1.4042 - categorical_crossentropy: 1.4042 - accuracy: 0.5819\n",
      "Epoch 33/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.3960 - categorical_crossentropy: 1.3960 - accuracy: 0.5829\n",
      "Epoch 34/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.3829 - categorical_crossentropy: 1.3829 - accuracy: 0.5874\n",
      "Epoch 35/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.3674 - categorical_crossentropy: 1.3674 - accuracy: 0.5900\n",
      "Epoch 36/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.3567 - categorical_crossentropy: 1.3567 - accuracy: 0.5919\n",
      "Epoch 37/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.3376 - categorical_crossentropy: 1.3376 - accuracy: 0.5978\n",
      "Epoch 38/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.3186 - categorical_crossentropy: 1.3186 - accuracy: 0.6025\n",
      "Epoch 39/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.3145 - categorical_crossentropy: 1.3145 - accuracy: 0.6026\n",
      "Epoch 40/80\n",
      "993/993 [==============================] - 3s 3ms/step - loss: 1.2949 - categorical_crossentropy: 1.2949 - accuracy: 0.6087\n",
      "Epoch 41/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.2701 - categorical_crossentropy: 1.2701 - accuracy: 0.6159\n",
      "Epoch 42/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.2591 - categorical_crossentropy: 1.2591 - accuracy: 0.6176\n",
      "Epoch 43/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.2412 - categorical_crossentropy: 1.2412 - accuracy: 0.6219\n",
      "Epoch 44/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.2334 - categorical_crossentropy: 1.2334 - accuracy: 0.6237\n",
      "Epoch 45/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.2134 - categorical_crossentropy: 1.2134 - accuracy: 0.6299\n",
      "Epoch 46/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.1947 - categorical_crossentropy: 1.1947 - accuracy: 0.6347\n",
      "Epoch 47/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.1777 - categorical_crossentropy: 1.1777 - accuracy: 0.6379\n",
      "Epoch 48/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.1727 - categorical_crossentropy: 1.1727 - accuracy: 0.6421\n",
      "Epoch 49/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.1460 - categorical_crossentropy: 1.1460 - accuracy: 0.6485\n",
      "Epoch 50/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.1386 - categorical_crossentropy: 1.1386 - accuracy: 0.6504\n",
      "Epoch 51/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.1145 - categorical_crossentropy: 1.1145 - accuracy: 0.6565\n",
      "Epoch 52/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.0971 - categorical_crossentropy: 1.0971 - accuracy: 0.6655\n",
      "Epoch 53/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.0896 - categorical_crossentropy: 1.0896 - accuracy: 0.6641\n",
      "Epoch 54/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.0707 - categorical_crossentropy: 1.0707 - accuracy: 0.6707\n",
      "Epoch 55/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.0591 - categorical_crossentropy: 1.0591 - accuracy: 0.6723\n",
      "Epoch 56/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.0385 - categorical_crossentropy: 1.0385 - accuracy: 0.6801\n",
      "Epoch 57/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.0306 - categorical_crossentropy: 1.0306 - accuracy: 0.6828\n",
      "Epoch 58/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 1.0104 - categorical_crossentropy: 1.0104 - accuracy: 0.6865\n",
      "Epoch 59/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.9924 - categorical_crossentropy: 0.9924 - accuracy: 0.6945\n",
      "Epoch 60/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.9865 - categorical_crossentropy: 0.9865 - accuracy: 0.6957\n",
      "Epoch 61/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.9681 - categorical_crossentropy: 0.9681 - accuracy: 0.7005\n",
      "Epoch 62/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.9544 - categorical_crossentropy: 0.9544 - accuracy: 0.7051\n",
      "Epoch 63/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.9492 - categorical_crossentropy: 0.9492 - accuracy: 0.7057\n",
      "Epoch 64/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.9242 - categorical_crossentropy: 0.9242 - accuracy: 0.7138\n",
      "Epoch 65/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.9210 - categorical_crossentropy: 0.9210 - accuracy: 0.7135\n",
      "Epoch 66/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.9000 - categorical_crossentropy: 0.9000 - accuracy: 0.7221\n",
      "Epoch 67/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.8916 - categorical_crossentropy: 0.8916 - accuracy: 0.7241\n",
      "Epoch 68/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.8831 - categorical_crossentropy: 0.8831 - accuracy: 0.7267\n",
      "Epoch 69/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.8661 - categorical_crossentropy: 0.8661 - accuracy: 0.7352\n",
      "Epoch 70/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.8510 - categorical_crossentropy: 0.8510 - accuracy: 0.7372\n",
      "Epoch 71/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.8515 - categorical_crossentropy: 0.8515 - accuracy: 0.7367\n",
      "Epoch 72/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.8265 - categorical_crossentropy: 0.8265 - accuracy: 0.7457\n",
      "Epoch 73/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.8310 - categorical_crossentropy: 0.8310 - accuracy: 0.7438\n",
      "Epoch 74/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.8153 - categorical_crossentropy: 0.8153 - accuracy: 0.7468\n",
      "Epoch 75/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.7994 - categorical_crossentropy: 0.7994 - accuracy: 0.7536\n",
      "Epoch 76/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.7901 - categorical_crossentropy: 0.7901 - accuracy: 0.7552\n",
      "Epoch 77/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.7862 - categorical_crossentropy: 0.7862 - accuracy: 0.7578\n",
      "Epoch 78/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.7686 - categorical_crossentropy: 0.7686 - accuracy: 0.7620\n",
      "Epoch 79/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.7631 - categorical_crossentropy: 0.7631 - accuracy: 0.7655\n",
      "Epoch 80/80\n",
      "993/993 [==============================] - 2s 2ms/step - loss: 0.7636 - categorical_crossentropy: 0.7636 - accuracy: 0.7616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x637ce4e10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(data_X, data_Y, batch_size=128, epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.exp(np.log(preds) / temperature)  # softmax\n",
    "    preds = preds / np.sum(preds)                #\n",
    "    probas = np.random.multinomial(1, preds, 1)  # sample index\n",
    "    return np.argmax(probas)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_poem(epoch, start_index, diversity, _):\n",
    "    \"\"\"Function invoked at end of each epoch. Prints generated text.\"\"\"\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = start_index\n",
    "    diversity = diversity\n",
    "\n",
    "    generated = ''\n",
    "    poemLines = sadPoems[start_index: start_index + seqlen]\n",
    "    generated += poemLines\n",
    "    print('----- Generating with seed: \"' + poemLines + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "        for t, char in enumerate(poemLines):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)\n",
    "        next_index = sample(preds[0, -1], diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        poemLines = poemLines[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Generating text after Epoch: 80\n",
      "----- Generating with seed: \"heir death wat...\n",
      "30       \\r\\r\\nImagine half your\"\n",
      "heir death wat...\n",
      "30       \\r\\r\\nImagine half your back again, a caplow my dad...\n",
      "6965     \\r\\r\\nI saw afle the day haig the poated sain who toull...\n",
      "13044    \\r\\r\\nThe casken an the day is a which here a mome the ...\n",
      "4319     \\r\\r\\n\\r\\r\\n\\r\\r\\n\\r\\r\\nSong ther and and o...\n",
      "626      \\r\\r\\nI saw must al my so ding the mouthers. I was not...\n",
      "11888    \\r\\r\\nI had a lotele has lood, to like there is go...\n",
      "10706    \\r\\r\\nI had my father said of the car\n"
     ]
    }
   ],
   "source": [
    "generating_poem(80, 100, .25, _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
